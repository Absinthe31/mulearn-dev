{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d80f8b44-b659-450c-90a8-5048d668cd88",
   "metadata": {},
   "source": [
    "## Mulearn optimization problem test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5798eb8-95a3-400c-b1b5-fa16d977e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kernel\n",
    "import numpy as np\n",
    "import cooper\n",
    "import torch\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e8d8a2-39c1-486f-8d0e-0058653b5b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow not available\n",
      "tensorflow not available\n"
     ]
    }
   ],
   "source": [
    "import __init__\n",
    "import distributions\n",
    "import kernel\n",
    "import fuzzifier\n",
    "import optimization\n",
    "\n",
    "reload(__init__)\n",
    "reload(distributions)\n",
    "reload(kernel)\n",
    "reload(fuzzifier)\n",
    "reload(optimization)\n",
    "\n",
    "from __init__ import *\n",
    "from distributions import *\n",
    "from kernel import *\n",
    "from fuzzifier import *\n",
    "from optimization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f1a9793-bb71-4d5b-9f92-fc9b7a087cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24393f5b-9b32-4841-8c50-8d3898e895d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a540af2-16ec-44e8-a5ef-f3b3266b7106",
   "metadata": {},
   "source": [
    "### $\\chi$ version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811c6a23-0c99-4d10-b8f7-225d06c154c9",
   "metadata": {},
   "source": [
    "$max \\sum_i{\\chi_ik_{ii} - \\sum_{i,j}\\chi_i\\chi_jk_{ij}}$\n",
    "\n",
    "where $k_{ij} = k(i,j)$, under constraints:\n",
    "\n",
    "$\\sum_i \\chi_i = 1$\n",
    "\n",
    "$-C(1 - \\mu_i) \\le \\chi_i \\le C \\mu_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62acd17c-26a4-4e0f-a280-37dc3c947278",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mulearnCMP(cooper.ConstrainedMinimizationProblem):\n",
    "    def __init__(self):\n",
    "        super().__init__(is_constrained=True)\n",
    "\n",
    "    def closure(self, k, mus, C, chis):\n",
    "\n",
    "        loss = -chis.dot(torch.diag(k,0)) + chis.dot(k.matmul(chis)) \n",
    "\n",
    "        eq_defect = torch.sum(chis) - 1\n",
    "\n",
    "        ineq_defect1 = -C*(1 - mus) - chis\n",
    "        ineq_defect2 = chis - C*mus\n",
    "\n",
    "        ineq_defect = torch.stack([ineq_defect1, ineq_defect2])\n",
    "        \n",
    "        return cooper.CMPState(loss=loss, ineq_defect=ineq_defect, eq_defect=eq_defect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "676c0a71-b944-4c4a-8dc7-51f04f94fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(k, mus, C, max_iter, lr, atol):\n",
    "\n",
    "    mus = torch.tensor(mus, dtype=torch.float64)\n",
    "\n",
    "    if type(k) != torch.Tensor:\n",
    "        k = torch.tensor(k, dtype=torch.float64)\n",
    "\n",
    "    cmp = mulearnCMP()\n",
    "    formulation = cooper.LagrangianFormulation(cmp)\n",
    "\n",
    "    #np.random.seed(42)\n",
    "    a = np.random.uniform(-0.1, 0.1, len(mus))\n",
    "    #a = np.zeros(len(mus))\n",
    "    \n",
    "    chis = torch.nn.Parameter(torch.tensor(a, dtype=torch.float64, requires_grad=True))\n",
    "\n",
    "    primal_optimizer = cooper.optim.ExtraAdam([chis], lr=lr)\n",
    "    dual_optimizer = cooper.optim.partial_optimizer(cooper.optim.ExtraAdam, lr=lr)\n",
    "    \n",
    "    constrained_optimizer = cooper.ConstrainedOptimizer(\n",
    "        formulation=formulation,\n",
    "        primal_optimizer=primal_optimizer,\n",
    "        dual_optimizer=dual_optimizer,\n",
    "    )\n",
    "\n",
    "    const1 = torch.tensor(1.0, dtype=torch.float64)\n",
    "    \n",
    "    gap = torch.tensor(torch.inf)\n",
    "    constr1, constr2, constr3 = False, False, False\n",
    "    opt_found = False\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    while (i < max_iter):\n",
    "        \n",
    "        constrained_optimizer.zero_grad()\n",
    "        \n",
    "        lagrangian = formulation.composite_objective(\n",
    "            cmp.closure, k, mus, C, chis\n",
    "        )\n",
    "        formulation.custom_backward(lagrangian)\n",
    "        \n",
    "        constrained_optimizer.step(cmp.closure, k, mus, C, chis)\n",
    "        \n",
    "        constr1 = almost_negative(formulation.cmp.state.ineq_defect[0], atol=atol)\n",
    "        constr2 = almost_negative(formulation.cmp.state.ineq_defect[1], atol=atol)\n",
    "        constr3 = torch.isclose(torch.sum(chis), const1, atol=atol)\n",
    "\n",
    "        gap = formulation.cmp.state.loss - formulation.dual_parameters[1]\n",
    "\n",
    "        \n",
    "        #print('i:', i, 'gap:', gap)\n",
    "        #print(constr1, constr2, constr3)\n",
    "\n",
    "        if (torch.abs(gap) <= 1e-2) and constr1 and constr2 and constr3:\n",
    "            opt_found = True\n",
    "            break\n",
    "        \n",
    "        i+=1\n",
    "\n",
    "\n",
    "    if not opt_found:\n",
    "        print('optimal values not found')\n",
    "    \n",
    "    return chis#optim_chis, minimum_loss\n",
    "\n",
    "        \n",
    "def generate_dataset(n_samples=10, n_features=1):\n",
    "\n",
    "    #random.seed(42)\n",
    "    \n",
    "    X = np.zeros((n_samples, n_features))\n",
    "\n",
    "    for elem in range(n_samples):\n",
    "        for dim in range(n_features):\n",
    "            X[elem][dim] = random.uniform(0,1)\n",
    "\n",
    "    gaussian = lambda x,var : (np.e ** (-(((x-0.5)*2)**2)/(2*var)))\n",
    "\n",
    "    y = np.zeros(n_samples)\n",
    "    \n",
    "    for elem in range(n_samples):\n",
    "        y[elem] = 1\n",
    "        for dim in range(n_features):\n",
    "            y[elem] *= gaussian(X[elem][dim], np.var([X[j][dim] for j in range(n_samples)]))\n",
    "                          \n",
    "    return X,y\n",
    "\n",
    "def almost_negative(tensor, atol):\n",
    "    return torch.isclose(tensor[torch.gt(tensor,0.0)], torch.tensor(0.0, dtype=torch.float64), atol=atol).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25a2a5d6-361b-4060-b1b1-042735ef1c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, mus = generate_dataset(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3788423-f9ee-4fa7-88cb-1e715025b4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.9381577968597412\n"
     ]
    }
   ],
   "source": [
    "kern = kernel.GaussianKernel()\n",
    "s = time.time()\n",
    "k = [[kern.compute(x1, x2) for x1 in X] for x2 in X]\n",
    "print('time:', time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8309b13e-f367-4d7e-811b-3956a7a32b96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.6869761943817139\n"
     ]
    }
   ],
   "source": [
    "C = 1\n",
    "\n",
    "torch.set_default_device('cpu')\n",
    "\n",
    "s = time.time()\n",
    "chis = train(k, mus, C, 5000, 1e-3, 0.01)\n",
    "#chis = train(k, mus, C)\n",
    "print('time:', time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7a22ce6-5c93-4b76-8da5-0f394ac0cb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optim not found\n",
      "time: 5.458599805831909\n"
     ]
    }
   ],
   "source": [
    "C = 1\n",
    "\n",
    "torch.set_default_device('cuda:0')\n",
    "\n",
    "s = time.time()\n",
    "chis, loss = train(k, mus, C, 1000, 1e-3, 1e-3)\n",
    "#chis = train(k, mus, C)\n",
    "print('time:', time.time() - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11165c2-efbc-4a07-9502-f580bd30a023",
   "metadata": {},
   "source": [
    "### $\\alpha$ and $\\beta$ version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cefdf69-fc0a-4a0d-a59c-d0eff9bbfe78",
   "metadata": {},
   "source": [
    "$max \\sum_i{(\\alpha_i \\mu_i - \\beta_i(1 - \\mu_i))k_{ii} - \\sum_{i,j}(\\alpha_i \\mu_i - \\beta_i(1 - \\mu_i))(\\alpha_j \\mu_j - \\beta_j(1 - \\mu_j))k_{ij}}$\n",
    "\n",
    "where $k_{ij} = k(i,j)$, under constraints:\n",
    "\n",
    "$\\sum_i \\alpha_i \\mu_i - \\beta_i(1 - \\mu_i) = 1$\n",
    "\n",
    "$0 \\le \\alpha_i,\\beta_i \\le C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ccd1eab-4e19-430b-a2a2-9cc45047f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mulearnCMP2(cooper.ConstrainedMinimizationProblem):\n",
    "    def __init__(self):\n",
    "        super().__init__(is_constrained=True)\n",
    "\n",
    "    def closure(self, k, mus, C, alphas, betas):\n",
    "\n",
    "        chis = alphas*mus + betas*(1-mus)\n",
    "\n",
    "        #print(chis)\n",
    "        \n",
    "        loss = -chis.dot(torch.diag(k,0)) + chis.dot(k.matmul(chis)) \n",
    "\n",
    "        eq_defect = torch.sum(chis) - 1\n",
    "\n",
    "        ineq_defect1 = alphas - C\n",
    "        ineq_defect2 = -alphas\n",
    "        ineq_defect3 = betas - C\n",
    "        ineq_defect4 = -betas\n",
    "        \n",
    "        ineq_defect = torch.stack([ineq_defect1, ineq_defect2, ineq_defect3, ineq_defect4])\n",
    "        \n",
    "        return cooper.CMPState(loss=loss, ineq_defect=ineq_defect, eq_defect=eq_defect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0e94c22-b21f-4f9e-a13e-a85777905624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(k, mus, C, max_iter, lr, atol):\n",
    "\n",
    "    mus = torch.tensor(mus, dtype=torch.float64)\n",
    "\n",
    "    k = torch.tensor(k, dtype=torch.float64)\n",
    "\n",
    "    cmp = mulearnCMP2()\n",
    "    formulation = cooper.LagrangianFormulation(cmp)\n",
    "\n",
    "    #np.random.seed(42)\n",
    "    a = np.random.uniform(-0.1, 0.1, len(mus))\n",
    "    b = np.random.uniform(-0.1, 0.1, len(mus))\n",
    "    \n",
    "    alphas = torch.nn.Parameter(torch.tensor(a, dtype=torch.float64, requires_grad=True))\n",
    "    betas = torch.nn.Parameter(torch.tensor(b, dtype=torch.float64, requires_grad=True))\n",
    "    \n",
    "    primal_optimizer = cooper.optim.ExtraAdam([alphas, betas], lr=lr)\n",
    "    dual_optimizer = cooper.optim.partial_optimizer(cooper.optim.ExtraAdam, lr=lr)\n",
    "    \n",
    "    constrained_optimizer = cooper.ConstrainedOptimizer(\n",
    "        formulation=formulation,\n",
    "        primal_optimizer=primal_optimizer,\n",
    "        dual_optimizer=dual_optimizer,\n",
    "    )\n",
    "\n",
    "    const1 = torch.tensor(0.0, dtype=torch.float64)\n",
    "    \n",
    "    gap = torch.tensor(torch.inf)\n",
    "    constr1, constr2, constr3, constr4, constr5= False, False, False, False, False\n",
    "    opt_found = False\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    while (i < max_iter):\n",
    "        \n",
    "        constrained_optimizer.zero_grad()\n",
    "        \n",
    "        lagrangian = formulation.composite_objective(\n",
    "            cmp.closure, k, mus, C, alphas, betas\n",
    "        )\n",
    "        formulation.custom_backward(lagrangian)\n",
    "        \n",
    "        constrained_optimizer.step(cmp.closure, k, mus, C, alphas, betas)\n",
    "        \n",
    "        constr1 = almost_negative(formulation.cmp.state.ineq_defect[0], atol=atol)\n",
    "        constr2 = almost_negative(formulation.cmp.state.ineq_defect[1], atol=atol)\n",
    "        constr3 = almost_negative(formulation.cmp.state.ineq_defect[2], atol=atol)\n",
    "        constr4 = almost_negative(formulation.cmp.state.ineq_defect[3], atol=atol)\n",
    "        constr5 = torch.isclose(formulation.cmp.state.eq_defect, const1, atol=atol)\n",
    "\n",
    "        gap = formulation.cmp.state.loss - formulation.dual_parameters[1]\n",
    "        \n",
    "        #print('i:', i, 'gap:', gap)\n",
    "        #print(constr1, constr2, constr3, constr4, constr5)\n",
    "\n",
    "        if (torch.abs(gap) <= 1e-2) and constr1 and constr2 and constr3 and constr4 and constr5:\n",
    "            opt_found = True\n",
    "            break\n",
    "        \n",
    "        i+=1\n",
    "\n",
    "\n",
    "    if not opt_found:\n",
    "        print('optimal values not found')\n",
    "\n",
    "    \n",
    "    return alphas*mus - betas*(1-mus)\n",
    "\n",
    "        \n",
    "def generate_dataset(n_samples=10, n_features=1):\n",
    "\n",
    "    #random.seed(42)\n",
    "    \n",
    "    X = np.zeros((n_samples, n_features))\n",
    "\n",
    "    for elem in range(n_samples):\n",
    "        for dim in range(n_features):\n",
    "            X[elem][dim] = random.uniform(0,1)\n",
    "\n",
    "    gaussian = lambda x,var : (np.e ** (-(((x-0.5)*2)**2)/(2*var)))\n",
    "\n",
    "    y = np.zeros(n_samples)\n",
    "    \n",
    "    for elem in range(n_samples):\n",
    "        y[elem] = 1\n",
    "        for dim in range(n_features):\n",
    "            y[elem] *= gaussian(X[elem][dim], np.var([X[j][dim] for j in range(n_samples)]))\n",
    "                          \n",
    "    return X, y\n",
    "\n",
    "def almost_negative(tensor, atol):\n",
    "    return torch.isclose(tensor[torch.gt(tensor,0.0)], torch.tensor(0.0, dtype=torch.float64), atol=atol).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a35ba830-1907-452d-a392-bef6d3664574",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, mus = generate_dataset(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e808629-31e2-47d5-8e34-5173c3f728fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.9422235488891602\n"
     ]
    }
   ],
   "source": [
    "kern = kernel.GaussianKernel()\n",
    "s = time.time()\n",
    "k = [[kern.compute(x1, x2) for x1 in X] for x2 in X]\n",
    "print('time:', time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72ca9b39-b4c8-4880-a2de-76114ed3d767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal values not found\n",
      "time: 10.48835301399231\n"
     ]
    }
   ],
   "source": [
    "C = 1\n",
    "\n",
    "torch.set_default_device('cpu')\n",
    "\n",
    "s = time.time()\n",
    "chis = train2(k, mus, C, 5000, 1e-3, 0.01)\n",
    "\n",
    "print('time:', time.time() - s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cooper",
   "language": "python",
   "name": "cooper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
